{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f40bdb",
   "metadata": {},
   "source": [
    "# 05_02: SOLUTION - Walk through of project solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8012d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = \"...\"\n",
    "USER = \"neo4j\"\n",
    "PWD = \"...\"\n",
    "OPENAI_API_KEY = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.graphs.graph_document import GraphDocument\n",
    "import os\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_neo4j import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.evaluation.qa.eval_chain import QAEvalChain\n",
    "from langchain.document_loaders import WikipediaLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d5899",
   "metadata": {},
   "source": [
    "Change this to output a snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = WikipediaLoader(query=\"Portugal\").load()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaefff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in text:\n",
    "    print(el.metadata['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(text)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e638fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(url=URI, username=USER, password=PWD)\n",
    "\n",
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd4acf3",
   "metadata": {},
   "source": [
    "Check this import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bbfe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '../data/portugal text.pdf'\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_documents = llm_transformer.convert_to_graph_documents(chunks)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3992a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d065047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_graph = Neo4jGraph(url=URI, username=USER, password=PWD, enhanced_schema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fe91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to\n",
    "answer questions about Portugal.\n",
    "Convert the user's question based on the schema.\n",
    "\n",
    "When you are presented with query properties such as id's like \"rock pools\",\n",
    "be sure to convert the first letter to capital case, such as \"Rock Pools\"\n",
    "before you run the Cypher query.\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=enhanced_graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Tell me about the African union?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04bee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to\n",
    "answer questions about Portugal.\n",
    "Convert the user's question based on the schema.\n",
    "\n",
    "When you are presented with query properties such as id's like \"rock pools\",\n",
    "be sure to convert the first letter to capital case, such as \"Rock Pools\"\n",
    "before you run the Cypher query.\n",
    "\n",
    "You also will want to remove words like \"the\" or \"an\" in front of entities.  For\n",
    "example, if I asked \"Tell me about the schengen area\", the entity is \"Schengen Area\"\n",
    "and NOT \"The Schengen Area\".\n",
    "\n",
    "For example, if I were to ask \"Tell me about the schengen area\",\" you should create\n",
    "a Cypher query that finds all nodes with the id \"Schengen Area\" and then find\n",
    "all nodes connected to those nodes and use those to forumulate your answer, like this:\n",
    "\n",
    "MATCH (a {{id: \"Schengen Area\"}})-[r]-(b)\n",
    "RETURN a, r, b\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=enhanced_graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25bae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Tell me about the African union?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63366fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Where can I go canyoning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcbfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to\n",
    "answer questions about Portugal.\n",
    "Convert the user's question based on the schema.\n",
    "\n",
    "When you are presented with query properties such as id's like \"rock pools\",\n",
    "be sure to convert the first letter to capital case, such as \"Rock Pools\"\n",
    "before you run the Cypher query.\n",
    "\n",
    "You also will want to remove words like \"the\" or \"an\" in front of entities.  For\n",
    "example, if I asked \"Tell me about the schengen area\", the entity is \"Schengen Area\"\n",
    "and NOT \"The Schengen Area\".\n",
    "\n",
    "For example, if I were to ask \"Tell me about the schengen area\",\" you should create\n",
    "a Cypher query that finds all nodes with the id \"Schengen Area\" and then find\n",
    "all nodes connected to those nodes and use those to forumulate your answer, like this:\n",
    "\n",
    "MATCH (a {{id: \"Schengen Area\"}})-[r]-(b)\n",
    "RETURN a, r, b\n",
    "\n",
    "Do NOT be very restrictive on the types of relationships you specify.  For example,\n",
    "if I ask \"Where can I go canyoning\", you should NOT specify the relationship type.\n",
    "Instead, use a Cypher query like this:\n",
    "\n",
    "MATCH (a {{id: \"Canyoning\"}})-[r]-(b:Place)\n",
    "RETURN a, r, b\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=enhanced_graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ecd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Where can I go on a cable car?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd15f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"query\": \"Where can I go kayaking?\",\n",
    "     \"answer\": \"Portugal, Mondego, or Zêzere\"},\n",
    "    {\"query\": \"How is Luis related to Isabella of Portugal?\", \n",
    "     \"answer\": \"They are siblings\"},\n",
    "    {\"query\": \"Where is Braga?\", \n",
    "     \"answer\": \"In the Minho Region\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0231363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_graph_rag(cypher_chain, eval_chain, examples):\n",
    "\n",
    "    # Generate predictions by querying the graph\n",
    "    predictions = []\n",
    "    for ex in examples:\n",
    "        graph_response = cypher_chain.invoke({\"query\": ex[\"query\"]})\n",
    "        predictions.append({\"result\": graph_response[\"result\"].strip()})\n",
    "\n",
    "    # Run evaluation\n",
    "    #eval_chain = QAEvalChain.from_llm(llm)\n",
    "    results = eval_chain.evaluate(examples, predictions)\n",
    "\n",
    "    # Print output\n",
    "    correct = 0\n",
    "    for i, res in enumerate(results):\n",
    "        print(f\"Query: {examples[i]['query']}\")\n",
    "        print(f\"Prediction from graph: {predictions[i]['result']}\")\n",
    "        print(f\"Gold answer: {examples[i]['answer']}\")\n",
    "        print(f\"Grade: {res['results']}\")\n",
    "        print(\"---\")\n",
    "        if res[\"results\"] == \"CORRECT\":\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(examples)\n",
    "    print(f\"Graph QA Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a76ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_graph_rag(cypher_chain, eval_chain, examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
