{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162596a7",
   "metadata": {},
   "source": [
    "# 04_07: SOLUTION - Evaluating your GraphRAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dcadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.evaluation.qa.eval_chain import QAEvalChain\n",
    "from langchain_neo4j import GraphCypherQAChain, Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "URI = os.getenv(\"NEO4J_URI\")\n",
    "USER = os.getenv(\"NEO4J_USER\")\n",
    "PWD = os.getenv(\"NEO4J_PWD\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb4be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_graph = Neo4jGraph(url=URI, username=USER, password=PWD, enhanced_schema=True)\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4o\", temperature=0)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"query\": \"What sports is the International Ski And Snowboard Federation responsible for?\",\n",
    "     \"answer\": \"Alpine Skiing, Freestyle Skiing, Snowboarding, Nordic Combined, Ski Jumping, Cross-Country Skiing\"},\n",
    "    {\"query\": \"What activity are ski poles not used in?\", \"answer\": \"Ski jumping\"},\n",
    "    {\"query\": \"Who do athletes get help from?\", \"answer\": \"Coaches, Peer Mentors, and Sports Psychologists\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chain = GraphCypherQAChain.from_llm(\n",
    "    graph=enhanced_graph,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_graph_rag(graph_chain, examples):\n",
    "\n",
    "    # Generate predictions by querying the graph\n",
    "    predictions = []\n",
    "    for ex in examples:\n",
    "        graph_response = graph_chain.invoke({\"query\": ex[\"query\"]})\n",
    "        predictions.append({\"result\": graph_response[\"result\"].strip()})\n",
    "\n",
    "    # Run evaluation\n",
    "    eval_chain = QAEvalChain.from_llm(llm)\n",
    "    results = eval_chain.evaluate(examples, predictions)\n",
    "\n",
    "    # Print output\n",
    "    correct = 0\n",
    "    for i, res in enumerate(results):\n",
    "        print(f\"Query: {examples[i]['query']}\")\n",
    "        print(f\"Prediction from graph: {predictions[i]['result']}\")\n",
    "        print(f\"Gold answer: {examples[i]['answer']}\")\n",
    "        print(f\"Grade: {res['results']}\")\n",
    "        print(\"---\")\n",
    "        if res[\"results\"] == \"CORRECT\":\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(examples)\n",
    "    print(f\"Graph QA Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa04b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_graph_rag(graph_chain, examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f185a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"query\": \"What activity is the Arlberg-Kandahar Races associated with?\",\n",
    "     \"answer\": \"The Arlberg-Kandahar Races are associated with Ski Touring.\"},\n",
    "    {\"query\": \"How does research play a role?\",\n",
    "     \"answer\": \"Research improves competition by looking at Surface Science and Friction Reduction and has implications for Competitive Performance and Recreational Enjoyment\"},\n",
    "    {\"query\": \"What techniques does the Skiing Community use to enhance Safety?\",\n",
    "     \"answer\": \"The Skiing Community innovates on Techniques that enhance Safety.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640972d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_graph_rag(graph_chain, examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "\n",
    "You are an expert Neo4j developer. Your job is to generate a Cypher query that will traverse exactly 1–3 hops out from your focus node.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Identify the main entity in the question and Capitalize Multi-Word IDs\n",
    "2. Write a variable-length MATCH using the new syntax:\n",
    "   MATCH path = (a {{id: \"{{entity}}\"}})-[r]-{{1,3}}(b)\n",
    "   RETURN path;\n",
    "\n",
    "Only return the Cypher query.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "enhanced_graph_chain = GraphCypherQAChain.from_llm(\n",
    "    graph=enhanced_graph,\n",
    "    llm=llm,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e57aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_graph_rag(enhanced_graph_chain, examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ed391",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER_SYNTHESIS_TEMPLATE = \"\"\"\n",
    "You have a list of variable‑length paths from Neo4j in the form:\n",
    "\n",
    "(path = [(a)-[:REL1]->(X)-[:REL2]->(b), …])\n",
    "\n",
    "Your job: extract the intermediate node X and the two relationship names REL1 and REL2,\n",
    "then produce one sentence of the form:\n",
    "\n",
    "“The {a.id} {rel1_verb} on {X.id} that {rel2_verb} {b.id}.”\n",
    "\n",
    "Example:\n",
    "\n",
    "Paths:\n",
    "1. (Skiing Community)-[INNOVATE]-(Techniques)-[ENHANCE]-(Safety)\n",
    "\n",
    "Answer:\n",
    "The Skiing Community innovates on Techniques that enhance Safety.\n",
    "\n",
    "Now, given:\n",
    "{paths}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "answer_prompt = PromptTemplate(\n",
    "    template=ANSWER_SYNTHESIS_TEMPLATE,\n",
    "    input_variables=[\"paths\"],\n",
    ")\n",
    "\n",
    "full_graph_chain = GraphCypherQAChain.from_llm(\n",
    "    llm=llm,\n",
    "    graph=enhanced_graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    answer_prompt=answer_prompt,      # ← override the summarizer\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f47775",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_graph_rag(full_graph_chain, examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
