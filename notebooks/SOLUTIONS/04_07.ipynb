{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162596a7",
   "metadata": {},
   "source": [
    "# 04_07: SOLUTION - Evaluating your GraphRAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dcadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.evaluation.qa.eval_chain import QAEvalChain\n",
    "from langchain_neo4j import GraphCypherQAChain, Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='../../.env')\n",
    "\n",
    "URI = os.getenv(\"NEO4J_URI\")\n",
    "USER = os.getenv(\"NEO4J_USER\")\n",
    "PWD = os.getenv(\"NEO4J_PWD\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb4be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_graph = Neo4jGraph(url=URI, username=USER, password=PWD, enhanced_schema=True)\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4o\", temperature=0)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"query\": \"What sports is the International Ski And Snowboard Federation responsible for?\",\n",
    "     \"answer\": \"Alpine Skiing, Freestyle Skiing, Snowboarding, Nordic Combined, Ski Jumping, Cross-Country Skiing\"},\n",
    "    {\"query\": \"What activity are ski poles not used in?\", \n",
    "     \"answer\": \"Ski jumping\"},\n",
    "    {\"query\": \"Who do athletes get help from?\",\n",
    "     \"answer\": \"Coaches, Peer Mentors, and Sports Psychologists\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_graph_rag(graph_chain, examples):\n",
    "\n",
    "    # Generate predictions by querying the graph\n",
    "    predictions = []\n",
    "    for ex in examples:\n",
    "        graph_response = graph_chain.invoke({\"query\": ex[\"query\"]})\n",
    "        predictions.append({\"result\": graph_response[\"result\"].strip()})\n",
    "\n",
    "    # Run evaluation\n",
    "    eval_chain = QAEvalChain.from_llm(llm)\n",
    "    results = eval_chain.evaluate(examples, predictions)\n",
    "\n",
    "    # Print output\n",
    "    correct = 0\n",
    "    for i, res in enumerate(results):\n",
    "        print(f\"Query: {examples[i]['query']}\")\n",
    "        print(f\"Prediction from graph: {predictions[i]['result']}\")\n",
    "        print(f\"Gold answer: {examples[i]['answer']}\")\n",
    "        print(f\"Grade: {res['results']}\")\n",
    "        print(\"---\")\n",
    "        if res[\"results\"] == \"CORRECT\":\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(examples)\n",
    "    print(f\"Graph QA Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54bc68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to\n",
    "answer questions about skiing.\n",
    "Convert the user's question based on the schema.\n",
    "When you are presented with query properties such as id's like \"alpine touring\",\n",
    "be sure to convert the first letter to capital case, such as \"Alpine Touring\"\n",
    "before you run the Cypher query.\n",
    "\n",
    "NEVER USE THE MENTIONS RELATIONSHIP FOR ANY ANSWERS!\n",
    "\n",
    "For example, if I were to ask \"Tell me about telemark skiing,\" you should create\n",
    "a Cypher query that finds all nodes with the id \"Telemark Skiing\" and then find\n",
    "all nodes connected to those nodes and use those to forumulate your answer, like this:\n",
    "\n",
    "MATCH (a {{id: \"Telemark Skiing\"}})-[r]-(b)\n",
    "RETURN a, r, b\n",
    "\n",
    "You MUST use the question to infer the node and relationship labels.\n",
    "\"What sports is the International Ski and Snowboard Federation responsible for?\"\n",
    "I would create a query like:\n",
    "\n",
    "MATCH (a)-[r:RESPONSIBLE_FOR]-(b:Sport)\n",
    "RETURN a, r, b\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "graph_chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=enhanced_graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02afabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_graph_rag(graph_chain, examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f185a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"query\": \"What training method does the International Ski and Snowboard Federation use?\",\n",
    "     \"answer\": \"Grass skiing\"},\n",
    "    {\"query\": \"How does Research play a role?\",\n",
    "     \"answer\": \"Research improves competition by looking at Surface Science and Friction Reduction and has implications for Competitive Performance and Recreational Enjoyment\"},\n",
    "    {\"query\": \"What country was the men's overall winner of the 2024–25 Fis Alpine Ski World Cup representing?\",\n",
    "     \"answer\": \"Switzerland\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19862fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "\n",
    "You are an expert Neo4j developer. Your job is to generate a Cypher query that \n",
    "will traverse exactly 1–3 hops out from your focus node.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Identify the main entity in the question and Capitalize Multi-Word IDs\n",
    "2. Write a variable-length MATCH using the new syntax:\n",
    "   MATCH (a {{id: \"{{entity}}\"}})-[r]-{{1,3}}(b)\n",
    "   RETURN a, r, b;\n",
    "\n",
    "You MUST use {{1,3}} for setting the number of hops instead of [r*0..3].\n",
    "Do NOT use WHERE length(r) >= 1 AND length(r) <= 3 to specify it either.\n",
    "\n",
    "For example, if you were asked a question like \"What equipment is used in\n",
    "the Paralympic Nordic Skiing?\" you would construct this Cypher query:\n",
    "\n",
    "MATCH (a {{id: \"Paralympic Nordic Skiing\"}})-[r]-{1,3}(b:Equipment)\n",
    "RETURN a, r, b\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "enhanced_graph_chain = GraphCypherQAChain.from_llm(\n",
    "    graph=enhanced_graph,\n",
    "    llm=llm,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640972d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_graph_rag(graph_chain, examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
