{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07c60ba",
   "metadata": {},
   "source": [
    "# 04_05: Evaluating your GraphRAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9601b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.evaluation.qa.eval_chain import QAEvalChain\n",
    "from langchain_neo4j import GraphCypherQAChain, Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "URI = os.getenv(\"NEO4J_URI\")\n",
    "USER = os.getenv(\"NEO4J_USER\")\n",
    "PWD = os.getenv(\"NEO4J_PWD\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(url=URI, username=USER, password=PWD)\n",
    "enhanced_graph = Neo4jGraph(url=URI, username=USER, password=PWD, enhanced_schema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"query\": \"What sports is the International Ski And Snowboard Federation responsible for?\",\n",
    "     \"answer\": \"Alpine Skiing, Freestyle Skiing, Snowboarding, Nordic Combined, Ski Jumping, Cross-Country Skiing\"},\n",
    "    {\"query\": \"What activity are ski poles not used in?\", \"answer\": \"Ski jumping\"},\n",
    "    {\"query\": \"Who do athletes get help from?\", \"answer\": \"Coaches, Peer Mentors, and Sports Psychologists\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4o\", temperature=0)\n",
    "graph_chain = GraphCypherQAChain.from_llm(\n",
    "    graph=enhanced_graph,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf024966",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for ex in examples:\n",
    "    graph_response = graph_chain.invoke({\"query\": ex[\"query\"]})\n",
    "    predictions.append({\"result\": graph_response[\"result\"].strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_chain = QAEvalChain.from_llm(llm)\n",
    "results = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb53e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"Query: {examples[i]['query']}\")\n",
    "    print(f\"Prediction from graph: {predictions[i]['result']}\")\n",
    "    print(f\"Gold answer: {examples[i]['answer']}\")\n",
    "    print(f\"Grade: {res['results']}\")\n",
    "    print(\"---\")\n",
    "    if res[\"results\"] == \"CORRECT\":\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(examples)\n",
    "print(f\"Graph QA Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
