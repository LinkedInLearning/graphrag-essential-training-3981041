{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115d381e",
   "metadata": {},
   "source": [
    "# 04_03: Using Knowledge Graphs in a GraphRAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40df1e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = \"...\"\n",
    "USER = \"neo4j\"\n",
    "PWD = \"...\"\n",
    "OPENAI_API_KEY = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.graphs.graph_document import GraphDocument\n",
    "import os\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_neo4j import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7770e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(url=URI, username=USER, password=PWD)\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9111db",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_graph = Neo4jGraph(url=URI, username=USER, password=PWD, enhanced_schema=True)\n",
    "print(enhanced_graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4o\", temperature=0)\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    graph=enhanced_graph, llm=llm, verbose=True, allow_dangerous_requests=True\n",
    ")\n",
    "response = chain.invoke({\"query\": \"What is slackcountry?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf87cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to\n",
    "answer questions about skiing.\n",
    "Convert the user's question based on the schema.\n",
    "When you are presented with query properties such as id's like \"alpine touring\",\n",
    "be sure to convert the first letter to capital case, such as \"Alpine Touring\"\n",
    "before you run the Cypher query.\n",
    "\n",
    "For example, if I were to ask \"Tell me about telemark skiing,\" you should create\n",
    "a Cypher query that finds all nodes with the id \"Telemark Skiing\" and then find\n",
    "all nodes connected to those nodes and use those to forumulate your answer, like this:\n",
    "\n",
    "MATCH (a {{id: \"Telemark Skiing\"}})-[r]-(b)\n",
    "RETURN a, r, b\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=enhanced_graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85592c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Tell me about ski touring?\"})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
