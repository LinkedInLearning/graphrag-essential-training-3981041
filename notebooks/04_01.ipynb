{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22628ec1",
   "metadata": {},
   "source": [
    "# 04_01: Creating a GraphRAG pipeline with LangChain to query your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f4a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_neo4j import GraphCypherQAChain, Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "URI = os.getenv(\"NEO4J_URI\")\n",
    "USER = os.getenv(\"NEO4J_USER\")\n",
    "PWD = os.getenv(\"NEO4J_PWD\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model_name=\"gpt-4o\")\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "graph = Neo4jGraph(url=URI, username=USER, password=PWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.query('MATCH (n) RETURN COUNT(n) as TOTAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c8ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
    "You are an expert Neo4j Developer translating user questions into Cypher to\n",
    "answer questions about skiing.\n",
    "Convert the user's question based on the schema.\n",
    "When you are presented with query properties such as id's like \"grass skiing\",\n",
    "be sure to convert the first letter to capital case, such as \"Grass Skiing\"\n",
    "before you run the Cypher query.\n",
    "\n",
    "Schema: {schema}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "cypher_generation_prompt = PromptTemplate(\n",
    "    template=CYPHER_GENERATION_TEMPLATE,\n",
    "    input_variables=[\"schema\", \"question\"],\n",
    ")\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph=graph,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5258697",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"What is a standard technique in alpine skiing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6dc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Tell me about ski touring.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Tell me about the biathalon.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"Tell me about any ski championships.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
